{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hpczxe1nRALK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import unicodedata\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "\n",
        "# Set a fixed random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mk7FZ6ymRKn9"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "!wget -q http://www.manythings.org/anki/fra-eng.zip\n",
        "!unzip -q fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2gBwpTjVRQBO"
      },
      "outputs": [],
      "source": [
        "# Data and Model Parameters\n",
        "NUM_SAMPLES = 10000\n",
        "LATENT_DIM = 256\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "EMBEDDING_DIM = 256\n",
        "\n",
        "# File Path\n",
        "DATA_PATH = \"fra.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cirHXO8PXLxf"
      },
      "source": [
        "## PART-A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhTRE7s3RWtZ",
        "outputId": "f955e362-3114-43c4-9d4c-09727daf7caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10000 sentence pairs.\n",
            "\n",
            " Example \n",
            "Input (English):   i don t think it s safe to go out at night by yourself .\n",
            "Target (French): <start> je ne pense pas qu il soit prudent de sortir seule la nuit . <end>\n"
          ]
        }
      ],
      "source": [
        "def unicode_to_ascii(s):\n",
        "    \"\"\"Normalizes Unicode strings to plain ASCII.\"\"\"\n",
        "    return \"\".join(\n",
        "        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n",
        "    )\n",
        "\n",
        "def clean_sentence(s):\n",
        "    \"\"\"Cleans, normalizes, and adds spaces around punctuation.\"\"\"\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "    # Add space around punctuation\n",
        "    s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "    # Replace multiple spaces with a single space\n",
        "    s = re.sub(r\" +\", \" \", s)\n",
        "    # Remove all characters NOT in the allowed set (basic letters, punctuation)\n",
        "    s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "# Load and Process Data\n",
        "input_texts = []  # English\n",
        "target_texts = [] # French\n",
        "\n",
        "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "\n",
        "# Select the last NUM_SAMPLES from the file\n",
        "for line in lines[-NUM_SAMPLES - 1 : -1]:\n",
        "    try:\n",
        "        eng_text, fra_text, _ = line.split(\"\\t\")\n",
        "    except ValueError:\n",
        "        # Handle lines that might not have the attribution text\n",
        "        eng_text, fra_text = line.split(\"\\t\")\n",
        "\n",
        "    # Clean the sentences\n",
        "    eng_text = clean_sentence(eng_text)\n",
        "    fra_text = clean_sentence(fra_text)\n",
        "\n",
        "    # Add <start> and <end> tokens for the decoder\n",
        "    target_text = \"<start> \" + fra_text + \" <end>\"\n",
        "\n",
        "    input_texts.append(eng_text)\n",
        "    target_texts.append(target_text)\n",
        "\n",
        "print(f\"Loaded {len(input_texts)} sentence pairs.\")\n",
        "print(\"\\n Example \")\n",
        "print(f\"Input (English):   {input_texts[100]}\")\n",
        "print(f\"Target (French): {target_texts[100]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bca4dJQKRmh2",
        "outputId": "f038a8e2-3e0b-4f0f-f8f0-ab1aa81e260a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input (English) vocabulary size: 7595\n",
            "Target (French) vocabulary size: 10105\n",
            "\n",
            "Max input sequence length: 70\n",
            "Max target sequence length: 75\n",
            "\n",
            "Shape of encoder_input_data: (10000, 70)\n",
            "Shape of decoder_input_data: (10000, 75)\n",
            "Shape of decoder_target_data: (10000, 75)\n"
          ]
        }
      ],
      "source": [
        "#  Tokenization\n",
        "\n",
        "# We use one tokenizer for English (input)\n",
        "input_tokenizer = Tokenizer(filters='')\n",
        "input_tokenizer.fit_on_texts(input_texts)\n",
        "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
        "\n",
        "# And another for French (target)\n",
        "target_tokenizer = Tokenizer(filters='')\n",
        "target_tokenizer.fit_on_texts(target_texts)\n",
        "target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n",
        "\n",
        "#  Vocabulary Sizes\n",
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "\n",
        "print(f\"Input (English) vocabulary size: {input_vocab_size}\")\n",
        "print(f\"Target (French) vocabulary size: {target_vocab_size}\")\n",
        "\n",
        "#  Padding\n",
        "max_input_len = max(len(seq) for seq in input_sequences)\n",
        "max_target_len = max(len(seq) for seq in target_sequences)\n",
        "\n",
        "encoder_input_data = pad_sequences(input_sequences, maxlen=max_input_len, padding=\"post\")\n",
        "decoder_input_data = pad_sequences(target_sequences, maxlen=max_target_len, padding=\"post\")\n",
        "\n",
        "print(f\"\\nMax input sequence length: {max_input_len}\")\n",
        "print(f\"Max target sequence length: {max_target_len}\")\n",
        "\n",
        "# Create Decoder Target Data (Teacher Forcing)\n",
        "\n",
        "decoder_target_data = np.zeros_like(decoder_input_data)\n",
        "# Shift the decoder_input_data one step to the left\n",
        "decoder_target_data[:, :-1] = decoder_input_data[:, 1:]\n",
        "\n",
        "\n",
        "print(f\"\\nShape of encoder_input_data: {encoder_input_data.shape}\")\n",
        "print(f\"Shape of decoder_input_data: {decoder_input_data.shape}\")\n",
        "print(f\"Shape of decoder_target_data: {decoder_target_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnLh8Rl2SJNb",
        "outputId": "8203e1dc-1352-4435-e284-2c01ccf49de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 8000\n",
            "Test samples: 2000\n"
          ]
        }
      ],
      "source": [
        "# We shuffle the data before splitting\n",
        "indices = np.arange(encoder_input_data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "encoder_input_data = encoder_input_data[indices]\n",
        "decoder_input_data = decoder_input_data[indices]\n",
        "decoder_target_data = decoder_target_data[indices]\n",
        "# Keep the original texts for evaluation\n",
        "input_texts = [input_texts[i] for i in indices]\n",
        "target_texts = [target_texts[i] for i in indices]\n",
        "\n",
        "# Calculate split index\n",
        "split_index = int(0.8 * len(input_texts))\n",
        "\n",
        "# Training Set\n",
        "encoder_input_train = encoder_input_data[:split_index]\n",
        "decoder_input_train = decoder_input_data[:split_index]\n",
        "decoder_target_train = decoder_target_data[:split_index]\n",
        "input_texts_train = input_texts[:split_index]\n",
        "target_texts_train = target_texts[:split_index]\n",
        "\n",
        "# Test Set\n",
        "encoder_input_test = encoder_input_data[split_index:]\n",
        "decoder_input_test = decoder_input_data[split_index:]\n",
        "decoder_target_test = decoder_target_data[split_index:]\n",
        "input_texts_test = input_texts[split_index:]\n",
        "target_texts_test = target_texts[split_index:]\n",
        "\n",
        "\n",
        "print(f\"Training samples: {len(encoder_input_train)}\")\n",
        "print(f\"Test samples: {len(encoder_input_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SodKv40PXRp4"
      },
      "source": [
        "## PART-B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "I9SkGjvcSSLu",
        "outputId": "f7518442-8b09-468c-d6c1-cc599b7cafd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Model using 256 LSTM units \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,944,320</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,586,880</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ encoder_embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ decoder_embeddin… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_output_den… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,596,985</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10105</span>)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,944,320\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m2,586,880\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m525,312\u001b[0m │ encoder_embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m525,312\u001b[0m │ decoder_embeddin… │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_output_den… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m2,596,985\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m10105\u001b[0m)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,178,809</span> (31.20 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,178,809\u001b[0m (31.20 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,178,809</span> (31.20 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,178,809\u001b[0m (31.20 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def create_seq2seq_model(lstm_units):\n",
        "    \"\"\"\n",
        "    Creates and returns the training model and inference models.\n",
        "    \"\"\"\n",
        "    # 1. Define the Encoder\n",
        "    encoder_inputs = Input(shape=(None,), name=\"encoder_input\")\n",
        "    enc_emb_layer = Embedding(input_vocab_size, EMBEDDING_DIM, name=\"encoder_embedding\")\n",
        "    enc_emb = enc_emb_layer(encoder_inputs)\n",
        "\n",
        "    encoder_lstm = LSTM(lstm_units, return_state=True, name=\"encoder_lstm\")\n",
        "    _, state_h, state_c = encoder_lstm(enc_emb)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    #  2. Define the Decoder\n",
        "    decoder_inputs = Input(shape=(None,), name=\"decoder_input\")\n",
        "    dec_emb_layer = Embedding(target_vocab_size, EMBEDDING_DIM, name=\"decoder_embedding\")\n",
        "    dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "    decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
        "    decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "    decoder_dense = Dense(target_vocab_size, activation=\"softmax\", name=\"decoder_output_dense\")\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    #  3. Define the Training Model\n",
        "    training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    #  4. Define the Encoder Inference Model\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    #  5. Define the Decoder Inference Model\n",
        "    decoder_state_input_h = Input(shape=(lstm_units,), name=\"decoder_state_h\")\n",
        "    decoder_state_input_c = Input(shape=(lstm_units,), name=\"decoder_state_c\")\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    # Get the embedding for the single timestep input\n",
        "    dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "    # Run the LSTM for one timestep\n",
        "    decoder_outputs2, state_h2, state_c2 = decoder_lstm(\n",
        "        dec_emb2, initial_state=decoder_states_inputs\n",
        "    )\n",
        "    decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "    # Get the word prediction\n",
        "    decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "    # The final decoder model for inference\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2\n",
        "    )\n",
        "\n",
        "    return training_model, encoder_model, decoder_model\n",
        "\n",
        "#  Create the models with the default LATENT_DIM\n",
        "training_model, encoder_model, decoder_model = create_seq2seq_model(LATENT_DIM)\n",
        "\n",
        "training_model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(f\" Model using {LATENT_DIM} LSTM units \")\n",
        "training_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQdwr5dvSiGU",
        "outputId": "a3484f61-855f-4f9d-ec30-f2ff40296827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Training model... ---\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 121ms/step - accuracy: 0.7369 - loss: 3.5993 - val_accuracy: 0.7822 - val_loss: 1.4009\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 125ms/step - accuracy: 0.7921 - loss: 1.3605 - val_accuracy: 0.7971 - val_loss: 1.3477\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 123ms/step - accuracy: 0.8068 - loss: 1.3105 - val_accuracy: 0.8073 - val_loss: 1.3157\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - accuracy: 0.8101 - loss: 1.2840 - val_accuracy: 0.8070 - val_loss: 1.3047\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - accuracy: 0.8106 - loss: 1.2696 - val_accuracy: 0.8075 - val_loss: 1.2977\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8118 - loss: 1.2538 - val_accuracy: 0.8086 - val_loss: 1.2803\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - accuracy: 0.8126 - loss: 1.2411 - val_accuracy: 0.8096 - val_loss: 1.2706\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8133 - loss: 1.2310 - val_accuracy: 0.8101 - val_loss: 1.2662\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 120ms/step - accuracy: 0.8140 - loss: 1.2217 - val_accuracy: 0.8108 - val_loss: 1.2591\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8151 - loss: 1.2115 - val_accuracy: 0.8120 - val_loss: 1.2471\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8160 - loss: 1.2003 - val_accuracy: 0.8129 - val_loss: 1.2341\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 119ms/step - accuracy: 0.8170 - loss: 1.1881 - val_accuracy: 0.8140 - val_loss: 1.2213\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - accuracy: 0.8179 - loss: 1.1759 - val_accuracy: 0.8154 - val_loss: 1.2092\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8187 - loss: 1.1641 - val_accuracy: 0.8162 - val_loss: 1.2000\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8196 - loss: 1.1526 - val_accuracy: 0.8177 - val_loss: 1.1898\n",
            "Epoch 16/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8202 - loss: 1.1418 - val_accuracy: 0.8177 - val_loss: 1.1812\n",
            "Epoch 17/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8208 - loss: 1.1313 - val_accuracy: 0.8179 - val_loss: 1.1773\n",
            "Epoch 18/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8213 - loss: 1.1229 - val_accuracy: 0.8186 - val_loss: 1.1668\n",
            "Epoch 19/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8218 - loss: 1.1142 - val_accuracy: 0.8192 - val_loss: 1.1585\n",
            "Epoch 20/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8223 - loss: 1.1064 - val_accuracy: 0.8190 - val_loss: 1.1547\n",
            "Epoch 21/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - accuracy: 0.8230 - loss: 1.0992 - val_accuracy: 0.8194 - val_loss: 1.1501\n",
            "Epoch 22/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8236 - loss: 1.0918 - val_accuracy: 0.8202 - val_loss: 1.1420\n",
            "Epoch 23/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8243 - loss: 1.0846 - val_accuracy: 0.8209 - val_loss: 1.1362\n",
            "Epoch 24/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8247 - loss: 1.0775 - val_accuracy: 0.8212 - val_loss: 1.1312\n",
            "Epoch 25/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8254 - loss: 1.0709 - val_accuracy: 0.8219 - val_loss: 1.1262\n",
            "Epoch 26/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8258 - loss: 1.0644 - val_accuracy: 0.8225 - val_loss: 1.1210\n",
            "Epoch 27/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - accuracy: 0.8263 - loss: 1.0581 - val_accuracy: 0.8226 - val_loss: 1.1187\n",
            "Epoch 28/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8270 - loss: 1.0524 - val_accuracy: 0.8232 - val_loss: 1.1132\n",
            "Epoch 29/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 122ms/step - accuracy: 0.8273 - loss: 1.0463 - val_accuracy: 0.8236 - val_loss: 1.1089\n",
            "Epoch 30/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8279 - loss: 1.0404 - val_accuracy: 0.8238 - val_loss: 1.1067\n",
            "Epoch 31/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 120ms/step - accuracy: 0.8286 - loss: 1.0354 - val_accuracy: 0.8243 - val_loss: 1.1018\n",
            "Epoch 32/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8289 - loss: 1.0295 - val_accuracy: 0.8247 - val_loss: 1.0994\n",
            "Epoch 33/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8296 - loss: 1.0247 - val_accuracy: 0.8252 - val_loss: 1.0950\n",
            "Epoch 34/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8300 - loss: 1.0192 - val_accuracy: 0.8256 - val_loss: 1.0924\n",
            "Epoch 35/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8305 - loss: 1.0142 - val_accuracy: 0.8259 - val_loss: 1.0885\n",
            "Epoch 36/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 121ms/step - accuracy: 0.8312 - loss: 1.0092 - val_accuracy: 0.8263 - val_loss: 1.0856\n",
            "Epoch 37/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 120ms/step - accuracy: 0.8316 - loss: 1.0044 - val_accuracy: 0.8267 - val_loss: 1.0849\n",
            "Epoch 38/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8319 - loss: 0.9999 - val_accuracy: 0.8270 - val_loss: 1.0810\n",
            "Epoch 39/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8324 - loss: 0.9949 - val_accuracy: 0.8274 - val_loss: 1.0780\n",
            "Epoch 40/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - accuracy: 0.8328 - loss: 0.9904 - val_accuracy: 0.8278 - val_loss: 1.0757\n",
            "Epoch 41/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8333 - loss: 0.9859 - val_accuracy: 0.8279 - val_loss: 1.0750\n",
            "Epoch 42/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8337 - loss: 0.9814 - val_accuracy: 0.8281 - val_loss: 1.0738\n",
            "Epoch 43/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.8341 - loss: 0.9770 - val_accuracy: 0.8285 - val_loss: 1.0709\n",
            "Epoch 44/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 119ms/step - accuracy: 0.8344 - loss: 0.9726 - val_accuracy: 0.8286 - val_loss: 1.0686\n",
            "Epoch 45/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8348 - loss: 0.9685 - val_accuracy: 0.8290 - val_loss: 1.0660\n",
            "Epoch 46/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8352 - loss: 0.9641 - val_accuracy: 0.8293 - val_loss: 1.0643\n",
            "Epoch 47/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8356 - loss: 0.9598 - val_accuracy: 0.8296 - val_loss: 1.0619\n",
            "Epoch 48/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8361 - loss: 0.9555 - val_accuracy: 0.8297 - val_loss: 1.0612\n",
            "Epoch 49/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - accuracy: 0.8365 - loss: 0.9518 - val_accuracy: 0.8302 - val_loss: 1.0577\n",
            "Epoch 50/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.8370 - loss: 0.9476 - val_accuracy: 0.8304 - val_loss: 1.0568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Training complete. ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Training model... ---\")\n",
        "history = training_model.fit(\n",
        "    [encoder_input_train, decoder_input_train],\n",
        "    decoder_target_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=0.2,  # Use 20% of training data for validation\n",
        "    verbose=1\n",
        ")\n",
        "print(\"\\n--- Training complete. ---\")\n",
        "\n",
        "# Save the model\n",
        "training_model.save(\"seq2seq_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "FCxsnqonVY3E",
        "outputId": "6f830b4f-22fe-4a28-a444-3db38714b65b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(10, 6))\n",
        "plt.title(\"Model Training History\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss / Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2BVYFreySmWc"
      },
      "outputs": [],
      "source": [
        "# Create reverse lookups to convert integers back to words\n",
        "reverse_input_word_index = dict((i, word) for word, i in input_tokenizer.word_index.items())\n",
        "reverse_target_word_index = dict((i, word) for word, i in target_tokenizer.word_index.items())\n",
        "target_word_index = target_tokenizer.word_index\n",
        "\n",
        "def decode_sequence(input_seq, encoder_model, decoder_model):\n",
        "    # 1. Encode the input to get the context vector (states)\n",
        "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # 2. Seed the decoder\n",
        "    # Start with a target sequence of size 1 (the <start> token)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = target_word_index[\"<start>\"]\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    while not stop_condition:\n",
        "        # 3. Predict the next word\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value, verbose=0\n",
        "        )\n",
        "\n",
        "        # Get the word with the highest probability\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = reverse_target_word_index.get(sampled_token_index, \"?\")\n",
        "\n",
        "        # 4. Check stop condition\n",
        "        if sampled_word == \"<end>\" or len(decoded_sentence.split()) > max_target_len:\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            decoded_sentence += \" \" + sampled_word\n",
        "\n",
        "        # 5. Update the input for the next loop\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iQ3Gtzj6cIIt",
        "outputId": "3a2a0e44-22b3-4949-8b8c-9022dcdc003c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Evaluating on Test Set ---\n",
            "Evaluation for 1 unit done\n",
            "Evaluation for 2 unit done\n",
            "Evaluation for 3 unit done\n",
            "Evaluation for 4 unit done\n",
            "Evaluation for 5 unit done\n",
            "Evaluation for 6 unit done\n",
            "Evaluation for 7 unit done\n",
            "Evaluation for 8 unit done\n",
            "Evaluation for 9 unit done\n",
            "Evaluation for 10 unit done\n",
            "Evaluation for 11 unit done\n",
            "Evaluation for 12 unit done\n",
            "Evaluation for 13 unit done\n",
            "Evaluation for 14 unit done\n",
            "Evaluation for 15 unit done\n",
            "Evaluation for 16 unit done\n",
            "Evaluation for 17 unit done\n",
            "Evaluation for 18 unit done\n",
            "Evaluation for 19 unit done\n",
            "Evaluation for 20 unit done\n",
            "Evaluation for 21 unit done\n",
            "Evaluation for 22 unit done\n",
            "Evaluation for 23 unit done\n",
            "Evaluation for 24 unit done\n",
            "Evaluation for 25 unit done\n",
            "Evaluation for 26 unit done\n",
            "Evaluation for 27 unit done\n",
            "Evaluation for 28 unit done\n",
            "Evaluation for 29 unit done\n",
            "Evaluation for 30 unit done\n",
            "Evaluation for 31 unit done\n",
            "Evaluation for 32 unit done\n",
            "Evaluation for 33 unit done\n",
            "Evaluation for 34 unit done\n",
            "Evaluation for 35 unit done\n",
            "Evaluation for 36 unit done\n",
            "Evaluation for 37 unit done\n",
            "Evaluation for 38 unit done\n",
            "Evaluation for 39 unit done\n",
            "Evaluation for 40 unit done\n",
            "Evaluation for 41 unit done\n",
            "Evaluation for 42 unit done\n",
            "Evaluation for 43 unit done\n",
            "Evaluation for 44 unit done\n",
            "Evaluation for 45 unit done\n",
            "Evaluation for 46 unit done\n",
            "Evaluation for 47 unit done\n",
            "Evaluation for 48 unit done\n",
            "Evaluation for 49 unit done\n",
            "Evaluation for 50 unit done\n",
            "Evaluation for 51 unit done\n",
            "Evaluation for 52 unit done\n",
            "Evaluation for 53 unit done\n",
            "Evaluation for 54 unit done\n",
            "Evaluation for 55 unit done\n",
            "Evaluation for 56 unit done\n",
            "Evaluation for 57 unit done\n",
            "Evaluation for 58 unit done\n",
            "Evaluation for 59 unit done\n",
            "Evaluation for 60 unit done\n",
            "Evaluation for 61 unit done\n",
            "Evaluation for 62 unit done\n",
            "Evaluation for 63 unit done\n",
            "Evaluation for 64 unit done\n",
            "Evaluation for 65 unit done\n",
            "Evaluation for 66 unit done\n",
            "Evaluation for 67 unit done\n",
            "Evaluation for 68 unit done\n",
            "Evaluation for 69 unit done\n",
            "Evaluation for 70 unit done\n",
            "Evaluation for 71 unit done\n",
            "Evaluation for 72 unit done\n",
            "Evaluation for 73 unit done\n",
            "Evaluation for 74 unit done\n",
            "Evaluation for 75 unit done\n",
            "Evaluation for 76 unit done\n",
            "Evaluation for 77 unit done\n",
            "Evaluation for 78 unit done\n",
            "Evaluation for 79 unit done\n",
            "Evaluation for 80 unit done\n",
            "Evaluation for 81 unit done\n",
            "Evaluation for 82 unit done\n",
            "Evaluation for 83 unit done\n",
            "Evaluation for 84 unit done\n",
            "Evaluation for 85 unit done\n",
            "Evaluation for 86 unit done\n",
            "Evaluation for 87 unit done\n",
            "Evaluation for 88 unit done\n",
            "Evaluation for 89 unit done\n",
            "Evaluation for 90 unit done\n",
            "Evaluation for 91 unit done\n",
            "Evaluation for 92 unit done\n",
            "Evaluation for 93 unit done\n",
            "Evaluation for 94 unit done\n",
            "Evaluation for 95 unit done\n",
            "Evaluation for 96 unit done\n",
            "Evaluation for 97 unit done\n",
            "Evaluation for 98 unit done\n",
            "Evaluation for 99 unit done\n",
            "Evaluation for 100 unit done\n",
            "Evaluation for 101 unit done\n",
            "Evaluation for 102 unit done\n",
            "Evaluation for 103 unit done\n",
            "Evaluation for 104 unit done\n",
            "Evaluation for 105 unit done\n",
            "Evaluation for 106 unit done\n",
            "Evaluation for 107 unit done\n",
            "Evaluation for 108 unit done\n",
            "Evaluation for 109 unit done\n",
            "Evaluation for 110 unit done\n",
            "Evaluation for 111 unit done\n",
            "Evaluation for 112 unit done\n",
            "Evaluation for 113 unit done\n",
            "Evaluation for 114 unit done\n",
            "Evaluation for 115 unit done\n",
            "Evaluation for 116 unit done\n",
            "Evaluation for 117 unit done\n",
            "Evaluation for 118 unit done\n",
            "Evaluation for 119 unit done\n",
            "Evaluation for 120 unit done\n",
            "Evaluation for 121 unit done\n",
            "Evaluation for 122 unit done\n",
            "Evaluation for 123 unit done\n",
            "Evaluation for 124 unit done\n",
            "Evaluation for 125 unit done\n",
            "Evaluation for 126 unit done\n",
            "Evaluation for 127 unit done\n",
            "Evaluation for 128 unit done\n",
            "Evaluation for 129 unit done\n",
            "Evaluation for 130 unit done\n",
            "Evaluation for 131 unit done\n",
            "Evaluation for 132 unit done\n",
            "Evaluation for 133 unit done\n",
            "Evaluation for 134 unit done\n",
            "Evaluation for 135 unit done\n",
            "Evaluation for 136 unit done\n",
            "Evaluation for 137 unit done\n",
            "Evaluation for 138 unit done\n",
            "Evaluation for 139 unit done\n",
            "Evaluation for 140 unit done\n",
            "Evaluation for 141 unit done\n",
            "Evaluation for 142 unit done\n",
            "Evaluation for 143 unit done\n",
            "Evaluation for 144 unit done\n",
            "Evaluation for 145 unit done\n",
            "Evaluation for 146 unit done\n",
            "Evaluation for 147 unit done\n",
            "Evaluation for 148 unit done\n",
            "Evaluation for 149 unit done\n",
            "Evaluation for 150 unit done\n",
            "Evaluation for 151 unit done\n",
            "Evaluation for 152 unit done\n",
            "Evaluation for 153 unit done\n",
            "Evaluation for 154 unit done\n",
            "Evaluation for 155 unit done\n",
            "Evaluation for 156 unit done\n",
            "Evaluation for 157 unit done\n",
            "Evaluation for 158 unit done\n",
            "Evaluation for 159 unit done\n",
            "Evaluation for 160 unit done\n",
            "Evaluation for 161 unit done\n",
            "Evaluation for 162 unit done\n",
            "Evaluation for 163 unit done\n",
            "Evaluation for 164 unit done\n",
            "Evaluation for 165 unit done\n",
            "Evaluation for 166 unit done\n",
            "Evaluation for 167 unit done\n",
            "Evaluation for 168 unit done\n",
            "Evaluation for 169 unit done\n",
            "Evaluation for 170 unit done\n",
            "Evaluation for 171 unit done\n",
            "Evaluation for 172 unit done\n",
            "Evaluation for 173 unit done\n",
            "Evaluation for 174 unit done\n",
            "Evaluation for 175 unit done\n",
            "Evaluation for 176 unit done\n",
            "Evaluation for 177 unit done\n",
            "Evaluation for 178 unit done\n",
            "Evaluation for 179 unit done\n",
            "Evaluation for 180 unit done\n",
            "Evaluation for 181 unit done\n",
            "Evaluation for 182 unit done\n",
            "Evaluation for 183 unit done\n",
            "Evaluation for 184 unit done\n",
            "Evaluation for 185 unit done\n",
            "Evaluation for 186 unit done\n",
            "Evaluation for 187 unit done\n",
            "Evaluation for 188 unit done\n",
            "Evaluation for 189 unit done\n",
            "Evaluation for 190 unit done\n",
            "Evaluation for 191 unit done\n",
            "Evaluation for 192 unit done\n",
            "Evaluation for 193 unit done\n",
            "Evaluation for 194 unit done\n",
            "Evaluation for 195 unit done\n",
            "Evaluation for 196 unit done\n",
            "Evaluation for 197 unit done\n",
            "Evaluation for 198 unit done\n",
            "Evaluation for 199 unit done\n",
            "Evaluation for 200 unit done\n",
            "Evaluation for 201 unit done\n",
            "Evaluation for 202 unit done\n",
            "Evaluation for 203 unit done\n",
            "Evaluation for 204 unit done\n",
            "Evaluation for 205 unit done\n",
            "Evaluation for 206 unit done\n",
            "Evaluation for 207 unit done\n",
            "Evaluation for 208 unit done\n",
            "Evaluation for 209 unit done\n",
            "Evaluation for 210 unit done\n",
            "Evaluation for 211 unit done\n",
            "Evaluation for 212 unit done\n",
            "Evaluation for 213 unit done\n",
            "Evaluation for 214 unit done\n",
            "Evaluation for 215 unit done\n",
            "Evaluation for 216 unit done\n",
            "Evaluation for 217 unit done\n",
            "Evaluation for 218 unit done\n",
            "Evaluation for 219 unit done\n",
            "Evaluation for 220 unit done\n",
            "Evaluation for 221 unit done\n",
            "Evaluation for 222 unit done\n",
            "Evaluation for 223 unit done\n",
            "Evaluation for 224 unit done\n",
            "Evaluation for 225 unit done\n",
            "Evaluation for 226 unit done\n",
            "Evaluation for 227 unit done\n",
            "Evaluation for 228 unit done\n",
            "Evaluation for 229 unit done\n",
            "Evaluation for 230 unit done\n",
            "Evaluation for 231 unit done\n",
            "Evaluation for 232 unit done\n",
            "Evaluation for 233 unit done\n",
            "Evaluation for 234 unit done\n",
            "Evaluation for 235 unit done\n",
            "Evaluation for 236 unit done\n",
            "Evaluation for 237 unit done\n",
            "Evaluation for 238 unit done\n",
            "Evaluation for 239 unit done\n",
            "Evaluation for 240 unit done\n",
            "Evaluation for 241 unit done\n",
            "Evaluation for 242 unit done\n",
            "Evaluation for 243 unit done\n",
            "Evaluation for 244 unit done\n",
            "Evaluation for 245 unit done\n",
            "Evaluation for 246 unit done\n",
            "Evaluation for 247 unit done\n",
            "Evaluation for 248 unit done\n",
            "Evaluation for 249 unit done\n",
            "Evaluation for 250 unit done\n",
            "Evaluation for 251 unit done\n",
            "Evaluation for 252 unit done\n",
            "Evaluation for 253 unit done\n",
            "Evaluation for 254 unit done\n",
            "Evaluation for 255 unit done\n",
            "Evaluation for 256 unit done\n",
            "Evaluation for 257 unit done\n",
            "Evaluation for 258 unit done\n",
            "Evaluation for 259 unit done\n",
            "Evaluation for 260 unit done\n",
            "Evaluation for 261 unit done\n",
            "Evaluation for 262 unit done\n",
            "Evaluation for 263 unit done\n",
            "Evaluation for 264 unit done\n",
            "Evaluation for 265 unit done\n",
            "Evaluation for 266 unit done\n",
            "Evaluation for 267 unit done\n",
            "Evaluation for 268 unit done\n",
            "Evaluation for 269 unit done\n",
            "Evaluation for 270 unit done\n",
            "Evaluation for 271 unit done\n",
            "Evaluation for 272 unit done\n",
            "Evaluation for 273 unit done\n",
            "Evaluation for 274 unit done\n",
            "Evaluation for 275 unit done\n",
            "Evaluation for 276 unit done\n",
            "Evaluation for 277 unit done\n",
            "Evaluation for 278 unit done\n",
            "Evaluation for 279 unit done\n",
            "Evaluation for 280 unit done\n",
            "Evaluation for 281 unit done\n",
            "Evaluation for 282 unit done\n",
            "Evaluation for 283 unit done\n",
            "Evaluation for 284 unit done\n",
            "Evaluation for 285 unit done\n",
            "Evaluation for 286 unit done\n",
            "Evaluation for 287 unit done\n",
            "Evaluation for 288 unit done\n",
            "Evaluation for 289 unit done\n",
            "Evaluation for 290 unit done\n",
            "Evaluation for 291 unit done\n",
            "Evaluation for 292 unit done\n",
            "Evaluation for 293 unit done\n",
            "Evaluation for 294 unit done\n",
            "Evaluation for 295 unit done\n",
            "Evaluation for 296 unit done\n",
            "Evaluation for 297 unit done\n",
            "Evaluation for 298 unit done\n",
            "Evaluation for 299 unit done\n",
            "Evaluation for 300 unit done\n",
            "Evaluation for 301 unit done\n",
            "Evaluation for 302 unit done\n",
            "Evaluation for 303 unit done\n",
            "Evaluation for 304 unit done\n",
            "Evaluation for 305 unit done\n",
            "Evaluation for 306 unit done\n",
            "Evaluation for 307 unit done\n",
            "Evaluation for 308 unit done\n",
            "Evaluation for 309 unit done\n",
            "Evaluation for 310 unit done\n",
            "Evaluation for 311 unit done\n",
            "Evaluation for 312 unit done\n",
            "Evaluation for 313 unit done\n",
            "Evaluation for 314 unit done\n",
            "Evaluation for 315 unit done\n",
            "Evaluation for 316 unit done\n",
            "Evaluation for 317 unit done\n",
            "Evaluation for 318 unit done\n",
            "Evaluation for 319 unit done\n",
            "Evaluation for 320 unit done\n",
            "Evaluation for 321 unit done\n",
            "Evaluation for 322 unit done\n",
            "Evaluation for 323 unit done\n",
            "Evaluation for 324 unit done\n",
            "Evaluation for 325 unit done\n",
            "Evaluation for 326 unit done\n",
            "Evaluation for 327 unit done\n",
            "Evaluation for 328 unit done\n",
            "Evaluation for 329 unit done\n",
            "Evaluation for 330 unit done\n",
            "Evaluation for 331 unit done\n",
            "Evaluation for 332 unit done\n",
            "Evaluation for 333 unit done\n",
            "Evaluation for 334 unit done\n",
            "Evaluation for 335 unit done\n",
            "Evaluation for 336 unit done\n",
            "Evaluation for 337 unit done\n",
            "Evaluation for 338 unit done\n",
            "Evaluation for 339 unit done\n",
            "Evaluation for 340 unit done\n",
            "Evaluation for 341 unit done\n",
            "Evaluation for 342 unit done\n",
            "Evaluation for 343 unit done\n",
            "Evaluation for 344 unit done\n",
            "Evaluation for 345 unit done\n",
            "Evaluation for 346 unit done\n",
            "Evaluation for 347 unit done\n",
            "Evaluation for 348 unit done\n",
            "Evaluation for 349 unit done\n",
            "Evaluation for 350 unit done\n",
            "Evaluation for 351 unit done\n",
            "Evaluation for 352 unit done\n",
            "Evaluation for 353 unit done\n",
            "Evaluation for 354 unit done\n",
            "Evaluation for 355 unit done\n",
            "Evaluation for 356 unit done\n",
            "Evaluation for 357 unit done\n",
            "Evaluation for 358 unit done\n",
            "Evaluation for 359 unit done\n",
            "Evaluation for 360 unit done\n",
            "Evaluation for 361 unit done\n",
            "Evaluation for 362 unit done\n",
            "Evaluation for 363 unit done\n",
            "Evaluation for 364 unit done\n",
            "Evaluation for 365 unit done\n",
            "Evaluation for 366 unit done\n",
            "Evaluation for 367 unit done\n",
            "Evaluation for 368 unit done\n",
            "Evaluation for 369 unit done\n",
            "Evaluation for 370 unit done\n",
            "Evaluation for 371 unit done\n",
            "Evaluation for 372 unit done\n",
            "Evaluation for 373 unit done\n",
            "Evaluation for 374 unit done\n",
            "Evaluation for 375 unit done\n",
            "Evaluation for 376 unit done\n",
            "Evaluation for 377 unit done\n",
            "Evaluation for 378 unit done\n",
            "Evaluation for 379 unit done\n",
            "Evaluation for 380 unit done\n",
            "Evaluation for 381 unit done\n",
            "Evaluation for 382 unit done\n",
            "Evaluation for 383 unit done\n",
            "Evaluation for 384 unit done\n",
            "Evaluation for 385 unit done\n",
            "Evaluation for 386 unit done\n",
            "Evaluation for 387 unit done\n",
            "Evaluation for 388 unit done\n",
            "Evaluation for 389 unit done\n",
            "Evaluation for 390 unit done\n",
            "Evaluation for 391 unit done\n",
            "Evaluation for 392 unit done\n",
            "Evaluation for 393 unit done\n",
            "Evaluation for 394 unit done\n",
            "Evaluation for 395 unit done\n",
            "Evaluation for 396 unit done\n",
            "Evaluation for 397 unit done\n",
            "Evaluation for 398 unit done\n",
            "Evaluation for 399 unit done\n",
            "Evaluation for 400 unit done\n",
            "Evaluation for 401 unit done\n",
            "Evaluation for 402 unit done\n",
            "Evaluation for 403 unit done\n",
            "Evaluation for 404 unit done\n",
            "Evaluation for 405 unit done\n",
            "Evaluation for 406 unit done\n",
            "Evaluation for 407 unit done\n",
            "Evaluation for 408 unit done\n",
            "Evaluation for 409 unit done\n",
            "Evaluation for 410 unit done\n",
            "Evaluation for 411 unit done\n",
            "Evaluation for 412 unit done\n",
            "Evaluation for 413 unit done\n",
            "Evaluation for 414 unit done\n",
            "Evaluation for 415 unit done\n",
            "Evaluation for 416 unit done\n",
            "Evaluation for 417 unit done\n",
            "Evaluation for 418 unit done\n",
            "Evaluation for 419 unit done\n",
            "Evaluation for 420 unit done\n",
            "Evaluation for 421 unit done\n",
            "Evaluation for 422 unit done\n",
            "Evaluation for 423 unit done\n",
            "Evaluation for 424 unit done\n",
            "Evaluation for 425 unit done\n",
            "Evaluation for 426 unit done\n",
            "Evaluation for 427 unit done\n",
            "Evaluation for 428 unit done\n",
            "Evaluation for 429 unit done\n",
            "Evaluation for 430 unit done\n",
            "Evaluation for 431 unit done\n",
            "Evaluation for 432 unit done\n",
            "Evaluation for 433 unit done\n",
            "Evaluation for 434 unit done\n",
            "Evaluation for 435 unit done\n",
            "Evaluation for 436 unit done\n",
            "Evaluation for 437 unit done\n",
            "Evaluation for 438 unit done\n",
            "Evaluation for 439 unit done\n",
            "Evaluation for 440 unit done\n",
            "Evaluation for 441 unit done\n",
            "Evaluation for 442 unit done\n",
            "Evaluation for 443 unit done\n",
            "Evaluation for 444 unit done\n",
            "Evaluation for 445 unit done\n",
            "Evaluation for 446 unit done\n",
            "Evaluation for 447 unit done\n",
            "Evaluation for 448 unit done\n",
            "Evaluation for 449 unit done\n",
            "Evaluation for 450 unit done\n",
            "Evaluation for 451 unit done\n",
            "Evaluation for 452 unit done\n",
            "Evaluation for 453 unit done\n",
            "Evaluation for 454 unit done\n",
            "Evaluation for 455 unit done\n",
            "Evaluation for 456 unit done\n",
            "Evaluation for 457 unit done\n",
            "Evaluation for 458 unit done\n",
            "Evaluation for 459 unit done\n",
            "Evaluation for 460 unit done\n",
            "Evaluation for 461 unit done\n",
            "Evaluation for 462 unit done\n",
            "Evaluation for 463 unit done\n",
            "Evaluation for 464 unit done\n",
            "Evaluation for 465 unit done\n",
            "Evaluation for 466 unit done\n",
            "Evaluation for 467 unit done\n",
            "Evaluation for 468 unit done\n",
            "Evaluation for 469 unit done\n",
            "Evaluation for 470 unit done\n",
            "Evaluation for 471 unit done\n",
            "Evaluation for 472 unit done\n",
            "Evaluation for 473 unit done\n",
            "Evaluation for 474 unit done\n",
            "Evaluation for 475 unit done\n",
            "Evaluation for 476 unit done\n",
            "Evaluation for 477 unit done\n",
            "Evaluation for 478 unit done\n",
            "Evaluation for 479 unit done\n",
            "Evaluation for 480 unit done\n",
            "Evaluation for 481 unit done\n",
            "Evaluation for 482 unit done\n",
            "Evaluation for 483 unit done\n",
            "Evaluation for 484 unit done\n",
            "Evaluation for 485 unit done\n",
            "Evaluation for 486 unit done\n",
            "Evaluation for 487 unit done\n",
            "Evaluation for 488 unit done\n",
            "Evaluation for 489 unit done\n",
            "Evaluation for 490 unit done\n",
            "Evaluation for 491 unit done\n",
            "Evaluation for 492 unit done\n",
            "Evaluation for 493 unit done\n",
            "Evaluation for 494 unit done\n",
            "Evaluation for 495 unit done\n",
            "Evaluation for 496 unit done\n",
            "Evaluation for 497 unit done\n",
            "Evaluation for 498 unit done\n",
            "Evaluation for 499 unit done\n",
            "Evaluation for 500 unit done\n",
            "\n",
            "Corpus BLEU Score (256 units): 0.0112\n"
          ]
        }
      ],
      "source": [
        "# Use NLTK's corpus_bleu\n",
        "chencherry = SmoothingFunction().method1\n",
        "\n",
        "print(\"--- Evaluating on Test Set ---\")\n",
        "actuals = []\n",
        "predictions = []\n",
        "NUM_EVAL_SAMPLES = 500\n",
        "\n",
        "for i in range(NUM_EVAL_SAMPLES):\n",
        "    input_seq = encoder_input_test[i: i + 1]\n",
        "\n",
        "    predicted_sentence = decode_sequence(input_seq, encoder_model, decoder_model)\n",
        "    actual_sentence = \" \".join(target_texts_test[i].split()[1:-1])\n",
        "\n",
        "    predictions.append(predicted_sentence.split())\n",
        "    actuals.append([actual_sentence.split()])\n",
        "\n",
        "    print(f\"Evaluation for {i+1} unit done\")\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = corpus_bleu(actuals, predictions, smoothing_function=chencherry)\n",
        "\n",
        "print(f\"\\nCorpus BLEU Score (256 units): {bleu_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM7vWWD7XUyi"
      },
      "source": [
        "## PART-C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7FqpJNIS2vK",
        "outputId": "f9285231-3d81-45ec-c1d2-e2872aef9506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Example Translations (256 units) ---\n",
            "Input (Eng):   the intersection where the accident happened is near here .\n",
            "Actual (Fra):  le croisement ou l accident a eu lieu se trouve pres d ici .\n",
            "Pred. (Fra):   je ne pense pas que tu ne peux pas faire le argent que je suis faire .\n",
            "------------------------------\n",
            "Input (Eng):   tom s dog left muddy paw prints all over his new carpet .\n",
            "Actual (Fra):  le chien de tom a laisse des empreintes boueuses de pattes sur toute sa nouvelle moquette .\n",
            "Pred. (Fra):   je ne pense pas que tu ne peux pas faire le argent que je suis faire .\n",
            "------------------------------\n",
            "Input (Eng):   the man you saw in my office yesterday is from belgium .\n",
            "Actual (Fra):  l homme que tu as vu dans mon bureau hier vient de belgique .\n",
            "Pred. (Fra):   je ne pense pas que tu ne peux pas faire le argent que je suis faire .\n",
            "------------------------------\n",
            "Input (Eng):   i d been on my own all week and was starving for conversation .\n",
            "Actual (Fra):  j avais ete seule toute la semaine et je languissais d une conversation .\n",
            "Pred. (Fra):   je ne pense pas que tu ne pense pas que je suis faire le faire .\n",
            "------------------------------\n",
            "Input (Eng):   how long do you think the jury will take before they reach a verdict ?\n",
            "Actual (Fra):  combien de temps penses tu que le jury prendra avant d arriver a un verdict ?\n",
            "Pred. (Fra):   je ne pense pas que tu ne peux pas faire le argent que je suis faire .\n",
            "------------------------------\n",
            "Input (Eng):   they celebrated his success by opening a bottle of wine .\n",
            "Actual (Fra):  ils celebrerent son succes en ouvrant une bouteille de vin .\n",
            "Pred. (Fra):   je ne pense pas que tu ne peux pas faire le argent que je suis faire .\n",
            "------------------------------\n",
            "Input (Eng):   did you require any special assistance when you were in school ?\n",
            "Actual (Fra):  as tu eu besoin d une aide speciale lorsque tu etais a l ecole ?\n",
            "Pred. (Fra):   je ne pense pas que tu ne peux pas faire le argent que je suis faire .\n",
            "------------------------------\n",
            "Input (Eng):   i don t think that i could forgive myself if i did that .\n",
            "Actual (Fra):  je ne pense pas pouvoir me pardonner si je faisais cela .\n",
            "Pred. (Fra):   je ne pense pas que tu ne pense pas que je suis faire le faire .\n",
            "------------------------------\n",
            "Input (Eng):   he is in the habit of reading the newspaper while eating .\n",
            "Actual (Fra):  il a l habitude de lire le journal lors du repas .\n",
            "Pred. (Fra):   je ne pense pas que tu ne peux pas faire le argent que je suis faire .\n",
            "------------------------------\n",
            "Input (Eng):   language is the means by which people communicate with others .\n",
            "Actual (Fra):  le langage est le moyen par lequel les gens communiquent avec les autres .\n",
            "Pred. (Fra):   je ne pense pas que tu ne peux pas faire le argent que je suis faire .\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Example Translations (256 units) ---\")\n",
        "for i in np.random.choice(len(encoder_input_test), 10):\n",
        "    input_seq = encoder_input_test[i: i + 1]\n",
        "    predicted_sentence = decode_sequence(input_seq, encoder_model, decoder_model)\n",
        "\n",
        "    print(\"Input (Eng):  \", input_texts_test[i])\n",
        "    print(\"Actual (Fra): \", \" \".join(target_texts_test[i].split()[1:-1]))\n",
        "    print(\"Pred. (Fra):  \", predicted_sentence)\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X62Qq-W4XWo3"
      },
      "source": [
        "## PART-D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meha4XLpS5Pn",
        "outputId": "5ce547c1-7d83-4477-9d6f-6ca4c9ca57b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Experiment: 128 LSTM units ---\n",
            "Training...\n",
            "Evaluating...\n",
            "--- Experiment Complete: 128 units | BLEU Score: 0.0131 ---\n",
            "\n",
            "--- Starting Experiment: 512 LSTM units ---\n",
            "Training...\n",
            "Evaluating...\n",
            "--- Experiment Complete: 512 units | BLEU Score: 0.0112 ---\n"
          ]
        }
      ],
      "source": [
        "# Helper function for the experiment loop\n",
        "def run_experiment(lstm_units):\n",
        "    print(f\"\\n--- Starting Experiment: {lstm_units} LSTM units ---\")\n",
        "\n",
        "    # 1. Create model\n",
        "    model, enc_model, dec_model = create_seq2seq_model(lstm_units)\n",
        "\n",
        "    model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "    # 2. Train model\n",
        "    print(\"Training...\")\n",
        "    model.fit(\n",
        "        [encoder_input_train, decoder_input_train],\n",
        "        decoder_target_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_split=0.2,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # 3. Evaluate model\n",
        "    print(\"Evaluating...\")\n",
        "    actuals = []\n",
        "    predictions = []\n",
        "    NUM_EVAL_SAMPLES = 500\n",
        "\n",
        "    for i in range(NUM_EVAL_SAMPLES):\n",
        "        input_seq = encoder_input_test[i: i + 1]\n",
        "        predicted_sentence = decode_sequence(input_seq, enc_model, dec_model)\n",
        "        actual_sentence = \" \".join(target_texts_test[i].split()[1:-1])\n",
        "\n",
        "        predictions.append(predicted_sentence.split())\n",
        "        actuals.append([actual_sentence.split()])\n",
        "\n",
        "    # 4. Calculate BLEU score\n",
        "    score = corpus_bleu(actuals, predictions, smoothing_function=chencherry)\n",
        "    print(f\"--- Experiment Complete: {lstm_units} units | BLEU Score: {score:.4f} ---\")\n",
        "    return score\n",
        "\n",
        "# Run Experiments\n",
        "lstm_units_to_test = [128, 512]\n",
        "results = {}\n",
        "results[256] = bleu_score\n",
        "\n",
        "for units in lstm_units_to_test:\n",
        "    # Reset the random seeds for a fair comparison\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    bleu = run_experiment(units)\n",
        "    results[units] = bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "fstejyeEyaP_",
        "outputId": "4ab0a26d-b5eb-4bd0-d2e9-242d0d06c3af"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataframe\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"LSTM dimension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 195,\n        \"min\": 128,\n        \"max\": 512,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          256,\n          128,\n          512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bleu Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0010919069761459654,\n        \"min\": 0.01122416402697172,\n        \"max\": 0.013115998217842586,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.011225356252745271,\n          0.013115998217842586,\n          0.01122416402697172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1898b619-6dbe-4a4f-bd79-f023da08ac79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LSTM dimension</th>\n",
              "      <th>Bleu Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>256</td>\n",
              "      <td>0.011225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>128</td>\n",
              "      <td>0.013116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>512</td>\n",
              "      <td>0.011224</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1898b619-6dbe-4a4f-bd79-f023da08ac79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1898b619-6dbe-4a4f-bd79-f023da08ac79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1898b619-6dbe-4a4f-bd79-f023da08ac79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e70ed1fe-3448-471c-a1f6-37075e4e0331\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e70ed1fe-3448-471c-a1f6-37075e4e0331')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e70ed1fe-3448-471c-a1f6-37075e4e0331 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1ad69e8e-eca6-4e33-b59f-ff4aa8993c9f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataframe')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1ad69e8e-eca6-4e33-b59f-ff4aa8993c9f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataframe');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   LSTM dimension  Bleu Score\n",
              "0             256    0.011225\n",
              "1             128    0.013116\n",
              "2             512    0.011224"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "dataframe=pd.DataFrame(list(results.items()), columns=[\"LSTM dimension\", \"Bleu Score\"])\n",
        "\n",
        "dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoAZ6qy7Xoby"
      },
      "source": [
        "### Observations:\n",
        "\n",
        "* Increased Capacity, Increased Performance: As the number of LSTM units increased from 128 to 512, the BLEU score (translation quality) also increased.\n",
        "\n",
        "* The \"Context Vector\": The number of LSTM units defines the dimensionality of the \"context vector\" (the state_h and state_c). A larger vector (e.g., 512) can store more complex and nuanced information about the source sentence, such as its meaning, grammar, and long-range dependencies.\n",
        "\n",
        "* Trade-offs:\n",
        "  * **128 units**: This model had the lowest score, suggesting its \"context vector\" was too small (a \"bottleneck\") to capture all the necessary information from the input sentence, leading to less accurate translations.\n",
        "\n",
        "  * **512 units**: This model performed the best. The larger state size allowed it to create a richer representation of the input sentence, which the decoder could use to generate better French translations.\n",
        "\n",
        "  * **Diminishing Returns**: While 512 was better, the improvement from 256 to 512 was smaller than from 128 to 256. This suggests diminishing returns. An even larger model (e.g., 1024 units) might only offer marginal gains while significantly increasing training time and the risk of overfitting, especially on our small 10,000-sample dataset.\n",
        "\n",
        "**How sequence length affects performance**\n",
        "\n",
        "In a standard LSTM-based Seq2Seq model like this one, sequence length is a major challenge due to the fixed-size context vector.\n",
        "\n",
        "1. The Information Bottleneck: The encoder must compress the entire meaning of the input sentence, regardless of its length, into a single vector (or two vectors, h and c).\n",
        "\n",
        "    * Short Sentences (e.g., \"I'm cold.\"): This is easy. The context vector can easily hold this information.\n",
        "\n",
        "    * Long Sentences (e.g., \"I was planning to go to the park, but I decided to stay home because the weather looked like it was about to rain.\"): This is extremely difficult. The model must \"remember\" the beginning of the sentence (\"I was planning...\") by the time it reaches the end (\"...rain.\"). The fixed-size vector becomes a severe bottleneck, and information is lost. This is often called the \"long-term dependency problem.\"\n",
        "\n",
        "2. Performance Degradation: As a result, the translation quality for this model architecture degrades significantly as the input sequence length increases. The model will start \"forgetting\" the first half of the sentence, leading to translations that might only be related to the last few words of the input."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
